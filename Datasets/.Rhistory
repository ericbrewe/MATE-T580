text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification))
top_n(toxic_comments,2)
toxic_comments %>%
group_by(classification) %>%
top_n(10) %>%
ungroup  %>%
)
toxic_comments %>%
group_by(classification) %>%
top_n(10) %>%
ungroup
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))
head(toxic_comments)
class(toxic_comments)
str(toxic_comments)
head(toxic_comments)
top_n(toxic_comments)
top_n(toxic_comments,10)
dim(top_n(toxic_comments,10))
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))  %>> toxic_comments[,c(3,1,2)]
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))  %>% toxic_comments[,c(3,1,2)]
head(toxic_comments)
toxic_comments = toxic_comments[,c(3,1,2)]
head(toxic_comments)
top_n(toxic_comments,5)
# Build a frequency table that contains comments of all 6 classes
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))
toxic_comments = toxic_comments[,c(3,1,2)]
toxic_comments %>%
group_by(classification) %>%
top_n(10) %>%
ungroup  %>%
ggplot(aes(reorder(word, n), n, fill="classification")) +
geom_bar(show.legend = FALSE, stat="identity") + coord_flip() +
facet_wrap(~classification, scales="free")
# Build a frequency table that contains comments of all 6 classes
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))
toxic_comments = toxic_comments[,c(3,1,2)]
toxic_comments %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(classification) %>%
top_n(10) %>%
ungroup  %>%
ggplot(aes(reorder(word, n), n, fill="classification")) +
geom_bar(show.legend = FALSE, stat="identity") + coord_flip() +
facet_wrap(~classification, scales="free")
# Build a frequency table that contains comments of all 6 classes
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))
toxic_comments = toxic_comments[,c(3,1,2)]
toxic_comments %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(classification) %>%
top_n(10) %>%
ungroup  %>%
ggplot(aes(word, n, fill="classification")) +
geom_bar(show.legend = FALSE, stat="identity") + coord_flip() +
facet_wrap(~classification, scales="free")
# Build a frequency table that contains comments of all 6 classes
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word))
toxic_comments = toxic_comments[,c(3,1,2)]
toxic_comments %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(classification) %>%
top_n(10) %>%
ungroup  %>%
ggplot(aes(word, n, fill=classification)) +
geom_bar(show.legend = FALSE, stat="identity") + coord_flip() +
facet_wrap(~classification, scales="free")
# Build a frequency table that contains comments of all 6 classes
toxic_comments <- bind_rows( text_tidy %>% filter(toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="toxic"),
text_tidy %>% filter(severe_toxic==1) %>% select(id, word) %>%
count(word, sort = TRUE) %>% mutate(classification="severe_toxic"),
text_tidy %>% filter(obscene==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="obscene"),
text_tidy %>% filter(threat==1) %>% select(id, word)    %>%
count(word, sort = TRUE) %>% mutate(classification="threat"),
text_tidy %>% filter(insult==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="insult"),
text_tidy %>% filter(identity_hate==1) %>% select(id, word)  %>%
count(word, sort = TRUE) %>% mutate(classification="identity_hate")) %>%
mutate(classification = as.factor(classification), word=as.factor(word)) %>%
select(classification, word, n)
# toxic_comments = toxic_comments[,c(3,1,2)]
toxic_comments %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(classification) %>%
top_n(10) %>%
ungroup  %>%
ggplot(aes(word, n, fill=classification)) +
geom_bar(show.legend = FALSE, stat="identity") + coord_flip() +
facet_wrap(~classification, scales="free")
library(readr, warn.conflicts = FALSE, quietly=TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
setwd('C:/users/maher/google drive/data science/kaggle/Toxic/')
train <- read_csv("input/train.csv", progress=FALSE)
test <- read_csv("input/test.csv", progress=FALSE)
paste(names(train), collapse = ", ")
paste(names(test), collapse = ", ")
paste(paste0(names(train)[3:8], " ", round(100*apply(train[,3:8], 2, sum)/nrow(train),2), "%"), collapse = ", ")
dfm <- data_frame(Class=names(apply(train[,3:8],2,sum)), Count=apply(train[,3:8],2,sum)) %>%
mutate(Class=reorder(Class,-Count))
ggplot(data=dfm, aes(x=Class, y=Count)) +  geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Count), vjust=0.9, color="white", size=3.5)
paste0("Comments with more than one class selected: ",  sum(apply(train[,3:8], 1, function(x){ sum(x)>1 } )) )
paste(paste0(names(train)[3:8], " ", round(100*apply(train[train$toxic==1, 3:8], 2, sum)/apply(train[, 3:8], 2, sum)), "%"), collapse = ", ")
paste(paste0(names(train)[3:8], " ", round(100*apply(train[train$severe_toxic==1, 3:8], 2, sum)/apply(train[, 3:8], 2, sum)), "%"), collapse = ", ")
paste(paste0(names(train)[3:8], " ", round(100*apply(train[train$obscene==1, 3:8], 2, sum)/apply(train[, 3:8], 2, sum)), "%"), collapse = ", ")
paste(paste0(names(train)[3:8], " ", round(100*apply(train[train$threat==1, 3:8], 2, sum)/apply(train[, 3:8], 2, sum)), "%"), collapse = ", ")
paste(paste0(names(train)[3:8], " ", round(100*apply(train[train$insult==1, 3:8], 2, sum)/apply(train[, 3:8], 2, sum)), "%"), collapse = ", ")
paste(paste0(names(train)[3:8], " ", round(100*apply(train[train$identity_hate==1, 3:8], 2, sum)/apply(train[, 3:8], 2, sum)), "%"), collapse = ", ")
library(tidytext)
text_tidy_raw <- train  %>%
select(id, comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate) %>%
unnest_tokens(word, comment_text)
text_tidy_raw  %>%
count(word, sort = TRUE) %>%
head(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill="steelblue") +
xlab(NULL) +
coord_flip()
data(stop_words)
text_tidy  <- text_tidy_raw %>%
anti_join(stop_words)
text_tidy  %>%
count(word, sort = TRUE) %>%
head(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill="steelblue") +
xlab(NULL) +
coord_flip()
filter()
?filter
dim(toxic_comments)
dim(filter(toxic_comments, classification=="toxic"))
dim(filter(toxic_comments, classification=="severe"))
dim(filter(toxic_comments, classification=="severe_toxic"))
library(wordcloud)
library(RColorBrewer)
library(reshape2)
paste("Wordcloud, first row order:", paste0(names(train)[3:5], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 1:3) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(6, 1), colors= brewer.pal(4, "Dark2")))
}
tt =  toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100)
dim(tt)
i=1
tt =  toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100)
head(tt)
i=2
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100)
head(tt)
tt =  toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100)
head(tt)
paste("Wordcloud, second row order:", paste0(names(train)[6:8], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 4:6) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(6, 1), colors= brewer.pal(4, "Dark2")))
}
paste("Wordcloud, second row order:", paste0(names(train)[6:8], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 4:6) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(50) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(6, 1), colors= brewer.pal(4, "Dark2")))
}
library(wordcloud)
library(RColorBrewer)
library(reshape2)
paste("Wordcloud, first row order:", paste0(names(train)[3:5], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 1:3) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(50) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(8, 1), colors= brewer.pal(4, "Dark2")))
}
library(wordcloud)
library(RColorBrewer)
library(reshape2)
paste("Wordcloud, first row order:", paste0(names(train)[3:5], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 1:3) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(8, 1), colors= brewer.pal(4, "Dark2")))
}
library(wordcloud)
library(RColorBrewer)
library(reshape2)
paste("Wordcloud, first row order:", paste0(names(train)[3:5], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 1:3) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(8, 1), colors= brewer.pal(4, "Dark2")))
}
library(wordcloud)
library(RColorBrewer)
library(reshape2)
paste("Wordcloud, first row order:", paste0(names(train)[3:5], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 1:3) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(8, 1), colors= brewer.pal(4, "Dark2")))
}
library(wordcloud)
library(RColorBrewer)
library(reshape2)
paste("Wordcloud, first row order:", paste0(names(train)[3:5], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 1:3) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(8, 1), colors= brewer.pal(4, "Dark2")))
}
paste("Wordcloud, second row order:", paste0(names(train)[6:8], collapse = ",   "))
par(mfrow=c(1,3), mai = c(1, 0.1, 0.1, 0.1))
for (i in 4:6) {
toxic_comments %>%
filter(classification==names(train)[2+i]) %>%
top_n(100) %>%
with(wordcloud(word, n, min.freq = 5, scale=c(8, 1), colors= brewer.pal(4, "Dark2")))
}
# Display percent of dataset that belongs to a certain toxic class
paste(paste0(names(train)[3:8], " ", round(100*apply(train[,3:8], 2, sum)/nrow(train),2), "%"), collapse = ", ")
# Bar plot of class counts
dfm <- data_frame(Class=names(apply(train[,3:8],2,sum)), n=apply(train[,3:8],2,sum)) %>%
mutate(Class=reorder(Class,-n))
ggplot(data=dfm, aes(x=Class, y=n)) +  geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Count), vjust=0.9, color="white", size=3.5)
# Display percent of dataset that belongs to a certain toxic class
paste(paste0(names(train)[3:8], " ", round(100*apply(train[,3:8], 2, sum)/nrow(train),2), "%"), collapse = ", ")
# Bar plot of class counts
dfm <- data_frame(Class=names(apply(train[,3:8],2,sum)), n=apply(train[,3:8],2,sum)) %>%
mutate(Class=reorder(Class,-n))
ggplot(data=dfm, aes(x=Class, y=n)) +  geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=n), vjust=0.9, color="white", size=3.5)
# Display percent of dataset that belongs to a certain toxic class
paste(paste0(names(train)[3:8], " ", round(100*apply(train[,3:8], 2, sum)/nrow(train),2), "%"), collapse = ", ")
# Bar plot of class counts
dfm <- data_frame(classification=names(apply(train[,3:8],2,sum)), n=apply(train[,3:8],2,sum)) %>%
mutate(classification=reorder(classification,-n))
ggplot(data=dfm, aes(x=classification, y=n)) +  geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=n), vjust=0.9, color="white", size=3.5)
library(tidytext)
tidy_text <- train  %>%
select(id, comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate) %>%
unnest_tokens(word, comment_text)
tidy_text  %>%
count(word, sort = TRUE) %>%
head(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill="steelblue") +
xlab(NULL) +
coord_flip()
# Remove stop words
data(stop_words)
tidy_text_nostops  <- tidy_text %>%
anti_join(stop_words)
# Plot top 10 words
tidy_text_nostops  %>%
count(word, sort = TRUE) %>%
head(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill="steelblue") +
xlab(NULL) +
coord_flip()
library(kerasR)
use_python
reticulate::use_python
?reticulate::use_python
library(kerasR)
?library
0.9826+0.8174+0.7826+0.7652+0.5652+0.4870+0.5913+0.7652+0.6783+0.7826+0.7652+0.8957+0.8435+0.7565+0.7478+3*0.6522+2*0.7130+4*0.5739
16.9/24
rank
mtcars
data(mtcars)
class(mtcars)
library(upquote)
install.packages("upquote")
?spread
library(tidyr)
?spread
420/21
21*15
library(glmnet)
data(iris)
iris$Species
levels(iris$Species)
glm
glm(Species~., family="gaussian")
glm(Species~., data=iris,iris family="gaussian")
glm(Species~., data=iris,family="gaussian")
glm(Species~., data=iris,family="gaussian")
library(tidyr)
library(dplyr)
iiris_binary <- iris %>%
mutate(dummy =
))
iris_binary <- iris %>%
mutate(dummy = 1)
head(iris_binary)
?spread
row(sums)
rowSums(sums)
rowSums
rowSums()
iris_binary <- iris %>%
mutate(id= 1:n(), dummy = 1) %>%
spread(Species, dummy, fill=0) %>%
select(-id) %>%
rename(Sepal.L = Sepal.Length, Sepal.W = Sepal.Width,
Petal.L = Petal.Length, Petal.W = Petal.Width)
plot(iris_binary$Sepal.L, iris_binary$setosa, xlab="Sepal length", ylab="Sesota(1=yes, 0=no)")
mod_glm <- glm(setosa~Sepal.L, iris_binary, family="gaussian")
mod_glm
lines(mod_glm)
line(mod_glm)
names(summary(mod_glm))
names(mod_glm)
mod_glm$R
mod_glm$fitted.values
install.packages("e1071")
library(e1071)
install.packages("e1071")
library(e1071)
getwd()
setwd('C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
df_titanic_test <- read_csv("titanic_test.csv")
library(readr)
setwd('C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
df_titanic_test <- read_csv("titanic_test.csv")
dim(df_titanic)
setwd('C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
df_titanic <- read_csv("titanic_train.csv")
dim(df_titanic)
dim(df_titanic_test)
id <- sample(1:nrow(df_titanic), round(0.8*nrow(df_titanic)))
id
df_test <- df_titanic[-id,]
df_train <- df_titanic[id,]
dim(df_test)
dim(df_train)
sum(df_train$Survived)/nrow(df_train)
sum(df_test$Survived)/nrow(df_test)
write_csv(df_test, "titanic_test.csv")
write_csv(df_train, "titanic_train.csv")
library(readr)
library(ggplot2)
setwd('C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
iris_4 <- read_csv("iris_alt.csv")
knitr::opts_knit$set(root.dir = 'C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
setwd('C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
setwd('C:/users/maher/Google Drive/GitHub/MATE-T580/Datasets/')
df_titanic <- read_csv("titanic_train.csv")
mod_titanic <- glm(Survived ~ Age + Sex + Fare, df_titanic, family = binomial)
names
names(mod_titanic)
mod_titanic$coefficients
e^0.012
exp(0.012)
names(df_test)
exp(0.012*73)
exp(-2.44)
exp(2.44)
df_titanic %>% group_by(Sex)
library(dplyr)
df_titanic %>% group_by(Sex) %>% summarize(sum(Survided)/n())
names(df_titanic)
df_titanic %>% group_by(Sex) %>% summarize(sum(Survived)/n())
0.754/0.19
.75/.25
.18/.82
3/.21
data("iris")
library(caret)
trControl <- trainControl(method = "cv", number = 5)
mod <- train(Species~., iris, method="glmnet", family="multinomial", lambda=0, metric="accuracy")
mod
trControl <- trainControl(method = "cv", number = 5)
grid <- expand.grid(alpha = 1, lambda = 0)
mod <- train(Species~., iris, method="glmnet", family="multinomial",  tuneGrid=grid, metric="accuracy")
mod
names(mod)
mod$finalModel
mod$results
mod$results$Accuracy
